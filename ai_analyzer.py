import json
from elasticsearch import Elasticsearch
import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
import warnings

warnings.filterwarnings('ignore')

# --- YAPILANDIRMA ---
ELASTIC_HOST = "https://localhost:9200"
ELASTIC_USERNAME = "elastic"
ELASTIC_PASSWORD = "yRFjrY9G-h9a188KWrjE"
INDEX_NAME = "threat_iocs"


# --- ELASTICSEARCH Ä°ÅLEMLERÄ° ---
def connect_to_elasticsearch():
    """Elasticsearch baÄŸlantÄ±sÄ±nÄ± kurar."""
    try:
        es = Elasticsearch(
            [ELASTIC_HOST],
            basic_auth=(ELASTIC_USERNAME, ELASTIC_PASSWORD),
            verify_certs=False,
            ssl_show_warn=False
        )
        if es.ping():
            return es
        else:
            print("âŒ HATA: Elasticsearch baÄŸlantÄ±sÄ± baÅŸarÄ±sÄ±z. Sunucu Ã§alÄ±ÅŸmÄ±yor olabilir.")
            return None
    except Exception as e:
        print(f"âŒ HATA: BaÄŸlantÄ± sÄ±rasÄ±nda genel hata: {e}")
        return None


def fetch_all_data(es_client):
    """Elasticsearch'ten tÃ¼m verileri Ã§eker."""
    print("â„¹ï¸ Elasticsearch'ten veri Ã§ekiliyor...")
    search_body = {
        "query": {"match_all": {}},
        "size": 10000
    }
    try:
        res = es_client.search(index=INDEX_NAME, body=search_body)
        data_list = [doc['_source'] for doc in res['hits']['hits']]

        if not data_list:
            print(f"UYARI: '{INDEX_NAME}' indeksinde hiÃ§ veri bulunamadÄ±. LÃ¼tfen db_uploader.py'yi Ã§alÄ±ÅŸtÄ±rÄ±n.")
            return pd.DataFrame()

        df = pd.DataFrame(data_list)
        print(f"âœ… Toplam {len(df)} adet veri Ã§ekildi.")
        return df
    except Exception as e:
        print(f"âŒ HATA: Veri Ã§ekme sÄ±rasÄ±nda hata (Ä°ndeks adÄ± doÄŸru mu?): {e}")
        return pd.DataFrame()


# --- MAKÄ°NE Ã–ÄRENÄ°MÄ° ANALÄ°ZÄ° ---
def perform_anomaly_detection(df):
    """Isolation Forest kullanarak anomali tespiti yapar ve skorlarÄ± ekler."""
    print("\nâš™ï¸ Makine Ã–ÄŸrenimi analizi baÅŸlatÄ±lÄ±yor...")

    features = ['confidence_score', 'extra_data_report_count']

    # 1. Feature Engineering
    if 'extra_data' in df.columns:
        def safe_json_parse(x):
            if pd.isna(x) or x == '':
                return {}
            if isinstance(x, dict):
                return x
            try:
                return json.loads(x) if isinstance(x, str) else {}
            except:
                return {}

        df['extra_data'] = df['extra_data'].apply(safe_json_parse)

        df['extra_data_report_count'] = df['extra_data'].apply(
            lambda x: x.get('report_count', 0) if isinstance(x, dict) else 0
        )

    df['confidence_score'] = pd.to_numeric(df['confidence_score'], errors='coerce').fillna(0)
    df['extra_data_report_count'] = pd.to_numeric(df['extra_data_report_count'], errors='coerce').fillna(0)

    # NaN veya Sonsuz deÄŸerleri temizleme/doldurma (ML modelinin Ã§Ã¶kmesini engeller)
    X = df[['confidence_score', 'extra_data_report_count']].values
    X[np.isnan(X)] = 0  # NaN'larÄ± 0 ile deÄŸiÅŸtir
    X[np.isinf(X)] = 0  # Sonsuz deÄŸerleri 0 ile deÄŸiÅŸtir

    # 2. Isolation Forest Modelini EÄŸitme
    model = IsolationForest(contamination='auto', random_state=42)

    try:
        model.fit(X)

        df['anomaly_label'] = model.predict(X)
        df['ml_risk_score'] = model.decision_function(X)

        # 3. Nihai Tehdit PuanÄ±nÄ± Hesaplama
        min_ml = df['ml_risk_score'].min()
        max_ml = df['ml_risk_score'].max()

        # ML skorunu 0 ile 1 arasÄ±na normalize et (dÃ¼ÅŸÃ¼k skor = yÃ¼ksek risk)
        df['ml_risk_score_norm'] = 1 - ((df['ml_risk_score'] - min_ml) / (max_ml - min_ml))

        # Final Skor: Mevcut Risk + ML TarafÄ±ndan Tespit Edilen Risk
        df['final_threat_score'] = (
                df['confidence_score'] * 0.7 +
                df['ml_risk_score_norm'] * 0.3
        )

        anomalies_found = len(df[df['anomaly_label'] == -1])
        print(f"âœ… Anomali tespiti tamamlandÄ±. Tespit edilen aykÄ±rÄ± IOC sayÄ±sÄ±: {anomalies_found}")

        return df

    except Exception as e:
        print(f"âŒ HATA: Makine Ã–ÄŸrenimi model hatasÄ±: {e}")
        return df


def update_elasticsearch(es_client, df):
    """Hesaplanan skorlarÄ± Elasticsearch'teki belgelere geri yazar."""
    print("\nâ¬†ï¸ Elasticsearch'teki belgeler gÃ¼ncelleniyor...")

    # NaN deÄŸerlerini 0'a Ã§evir
    df['final_threat_score'] = df['final_threat_score'].fillna(0)
    df['ml_risk_score'] = df['ml_risk_score'].fillna(0)

    df_update = df[['value', 'ioc_type', 'final_threat_score', 'ml_risk_score', 'anomaly_label']].copy()

    success_count = 0

    try:
        for index, row in df_update.iterrows():
            # GÃ¼ncellenecek skorlarÄ± ve etiketleri hazÄ±rla
            update_data = {
                "final_threat_score": float(row['final_threat_score']),
                "ml_risk_score": float(row['ml_risk_score']),
                "anomaly_label": int(row['anomaly_label'])
            }

            # Belgeyi bulmak iÃ§in sorgu
            search_query = {
                "query": {
                    "bool": {
                        "must": [
                            {"term": {"value": row['value']}},
                            {"term": {"ioc_type": row['ioc_type']}}
                        ]
                    }
                }
            }

            res_search = es_client.search(index=INDEX_NAME, body=search_query, size=1)

            if res_search['hits']['total']['value'] > 0:
                doc_id = res_search['hits']['hits'][0]['_id']

                # Belgeyi skorlarla gÃ¼ncelle
                es_client.update(index=INDEX_NAME, id=doc_id, body={"doc": update_data})
                success_count += 1

                if row['anomaly_label'] == -1:
                    print(f"   ğŸš¨ ANOMALÄ° TESPÄ°T EDÄ°LDÄ°: {row['value']} - Final Risk: {row['final_threat_score']:.2f}")

    except Exception as e:
        print(f"âŒ HATA: Elasticsearch gÃ¼ncelleme sÄ±rasÄ±nda hata: {e}")

    print(f"âœ… {success_count} adet belge gÃ¼ncellendi.")


def main():
    """AI analiz akÄ±ÅŸÄ±nÄ± yÃ¶netir."""
    es = connect_to_elasticsearch()
    if es is None:
        return

    df = fetch_all_data(es)
    if df.empty:
        return

    df_analyzed = perform_anomaly_detection(df)

    if not df_analyzed.empty:
        update_elasticsearch(es, df_analyzed)

    print(f"\n--- AI Analizi ve GÃ¼ncelleme TAMAMLANDI ---")


if __name__ == "__main__":
    main()
